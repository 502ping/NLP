import pandas as pd
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# Read dataset and observe features
df = pd.read_csv('.../text.tsv', sep='\t', header=None)
df.columns = ['ID', 'label' ...  'context']
print(df.shape)
print(df.head(10))


# The preprocessor function: pre(), the incoming argument is the header name of the dataset (df.column)
# Function: 1. View the number of words; 2. View the number of stop words; 3. Check whether there is capitalization;
# 4. Convert all to lowercase; 5. Remove punctuation; 6. Remove stop words; 7. View common words; 8. View scarce words
# 9. Word spelling correction; 10.Stemming
def pre(string):

    # 1.View the number of words
    df['word_count'] = df[string].apply(lambda x: len(str(x).split(" ")))
    print("No. of words:", df[[string, 'word_count']].head())
    print("*************************************************")
   
   # 2.View the number of stop words
    stop = stopwords.words('english')
    df['stopwords'] = df[string].apply(lambda sen: len([x for x in str(sen).split() if x in stop]))
    print("No. of stop words:ï¼š", df[[string, 'stopwords']].head())
    print("*************************************************")
   
   # 3.Check whether there is capitalization
    df['upper'] = df[string].apply(lambda sen: len([x for x in str(sen).split() if x.isupper()]))
    print("If there is a case:", df[[string, 'upper']].head())
    print("*************************************************")
   
   # 4.Convert all to lowercase
    df[string, 'statement'] = df[string].apply(lambda sen: " ".join(x.lower() for x in str(sen).split()))
    
   # 5.Remove punctuation
    df[string] = df[string].str.replace('[^\w\s]', '')
    
   # 6.Remove stop words
    stop = stopwords.words('english')
    df[string] = df[string].apply(lambda sen: " ".join(x for x in str(sen).split() if x not in stop))
    
   # 7.View common words
    freq = pd.Series(' '.join(df[string]).split()).value_counts()[:10]
    print("The common words:", freq, "\n*************************************************")
   
   # 8.View scarce words
    lack = pd.Series(' '.join(df['context']).split()).value_counts()[-10:]
    print("The scarce word", lack)
    print("*************************************")
   
   # 9.Word spelling correction
    correction = df['context'][:len(df['context'])].apply(lambda x: str(TextBlob(x).correct()))
    print("The result of word recorrection:\n", correction)
    print("*************************************")
    
   # 10.Stemming
    st = PorterStemmer()
    stem = df[string][:len(df[string])].apply(lambda x: " ".join([st.stem(word) for word in str(x).split()]))
    print(stem, "\n*********************** Ending **************************")


# Test function pre()
pre('context')
pre('statement')
